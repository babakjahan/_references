When running Gunicorn inside a Docker container, it's important to handle log files in a way that respects the ephemeral nature of containers. Here are the best practices for storing Gunicorn logs in this scenario:

1. **Use Docker's Logging Drivers**: By default, Gunicorn logs to stdout and stderr. Docker can capture these logs automatically through its logging drivers. The logs can then be viewed using `docker logs [container_id]`. This method is simple and leverages Docker's built-in logging capabilities.

2. **Mount a Volume for Log Files**: If you prefer to have Gunicorn logs written to a file, you can redirect them to a file inside a mounted volume. This approach ensures that logs persist even if the container is destroyed and makes it easier to integrate with external log management tools. For example:

   ```bash
   docker run -v /path/on/host/logs:/path/in/container/logs your-image
   ```

   In this command, `/path/on/host/logs` is a directory on the Docker host, and `/path/in/container/logs` is the directory inside the container where Gunicorn is configured to write its logs.

3. **Integrate with External Logging Systems**: For more sophisticated logging needs, consider integrating with external logging systems like ELK (Elasticsearch, Logstash, Kibana), Splunk, or Fluentd. These systems can aggregate logs from multiple sources, including Docker containers, and offer advanced features like search, analysis, and visualization.

4. **Implement Log Rotation**: Whether you are logging to stdout/stderr or to a file, ensure that log rotation is implemented. This can be handled by Docker's log rotation capabilities or by external log management tools. Log rotation prevents logs from consuming too much disk space.

5. **Configuration in Gunicorn**: You can configure Gunicorn to specify the log file and log level. If you're writing to a file, direct these logs to a path within the mounted volume.

6. **Centralized Log Management in Microservices Architecture**: If you're running multiple containers or services, it's a good practice to have a centralized log management system. This approach allows for better oversight and analysis of logs from all services.

Each of these methods has its own advantages and can be chosen based on the specific requirements of your deployment environment and the scale of your application. For most simple use cases, relying on Docker's logging mechanisms (stdout and stderr) is sufficient and the easiest to set up. For more complex scenarios, especially in a microservices architecture, integrating with an external logging system might be more appropriate.